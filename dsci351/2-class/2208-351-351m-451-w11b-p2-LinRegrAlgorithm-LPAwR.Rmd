---
title: "CWRU DSCI351-351M-453: Week11b-p-Simple-LinRegrAlgorithm-LPAwR"
subtitle: "2008-351-351m-451-w11b-p-LinRegrAlgo-LPAwR"
author: "Profs: R. H. French, L. S. Bruckman, P. Leu, K. Davis, S. Cirlos"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: TRUE
    number_sections: TRUE
    toc_depth: 6
    highlight: tango
  html_notebook:
  html_document:
    css: ../lab.css
    highlight: pygments
    theme: cerulean
    toc: yes
    toc_depth: 6
    toc_float: yes
    df_print: paged
urlcolor: blue
always_allow_html: true
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = FALSE, # if TRUE knitr will cache results to reuse in future knits
  fig.width = 6, # the width for plots created by code chunk
  fig.height = 6, # the height for plots created by code chunk
  fig.align = 'center', # how to align graphics. 'left', 'right', 'center'
  dpi = 300, 
  dev = 'png', # Makes each fig a png, and avoids plotting every data point
  # eval = FALSE, # if FALSE, then the R code chunks are not evaluated
  # results = 'asis', # knitr passes through results without reformatting
  echo = TRUE, # if FALSE knitr won't display code in chunk above it's results
  message = TRUE, # if FALSE knitr won't display messages generated by code
  strip.white = TRUE, # if FALSE knitr won't remove white spaces at beg or end of code chunk
  warning = TRUE, # if FALSE knitr won't display warning messages in the doc
  error = TRUE) # report errors
  # options(tinytex.verbose = TRUE)
```

\setcounter{section}{12}
\setcounter{subsection}{2}
\setcounter{subsubsection}{2}

#### Understanding simple linear regression
 
##### Build and use our own simple linear regression algorithm

  - Create multiple linear regression models in R
  - Perform diagnostic tests of such models
  - Score new data using a linear regression model
  - Examine how well the model predicts the new data

Regression seeks to obtain the model coefficients

  - that explain the variable's relationship the best 
  - but such a model only seldom reflects the relationship entirely

Indeed, measurement error, 

  - And also attributes that are not included in the analysis 
    - affect also the data. 

The model residuals 

  - express the deviation of the observed data points 
    - to the model. 

The residual's value 

  - is the vertical distance from a point 
    - to the regression line. 

#### Let's examine this with an example of the Fisher's/Anderson's iris dataset. 

- We have already seen that the dataset contains data about iris flowers. 

For the purpose of this example, 

  - we will consider the petal length as the response
    - sometimes the response is referred to as the "criterion"
  - and the petal width as the predictor 

```{r}
plot(
  iris$Petal.Length ~ iris$Petal.Width,
  main = "Relationship between petal length and petal width",
  xlab = "Petal width",
  ylab = "Petal length"
)
iris.lm = lm(iris$Petal.Length ~ iris$Petal.Width)
abline(iris.lm)
```

##### Computing the intercept and slope coefficient

```{r}
SlopeCoef = cor(iris$Petal.Length, iris$Petal.Width) *
  (sd(iris$Petal.Length) / sd(iris$Petal.Width))
SlopeCoef

coeffs = function(y, x) {
  ((length(y) * sum(y * x)) -
     (sum(y) * sum(x)))  /
    (length(y) * sum(x ^ 2) - sum(x) ^ 2)
}

coeffs(iris$Petal.Length, iris$Petal.Width)
```

##### Now make your linear regression function

```{r}
iris.lm

regress =  function(y, x) {
  slope = coeffs(y, x)
  intercept = mean(y) - (slope * mean(x))
  model = c(intercept, slope)
  names(model) = c("intercept", "slope")
  model
}
```

##### Now perform regression on Petal Length and Petal Width

```{r}
model = regress(iris$Petal.Length, iris$Petal.Width)
model
```

##### Obtaining the residuals

```{r}
resids = function(y, x, model) {
  y - model[1] - (model[2] * x)
}

Residuals = resids(iris$Petal.Length, iris$Petal.Width, model)

head(round(Residuals, 2))

par(mfrow = c(2, 2))
plot(iris.lm)
```

##### Computing the significance of the coefficients 

- This is also the uncertainty 

  - in your regression coefficients
  
```{r}
Significance = function(y, x, model) {
  SSE = sum(resids(y, x, model) ^ 2)
  DF = length(y) - 2
  S = sqrt(SSE / DF)
  SEslope = S / sqrt(sum((x - mean(x)) ^ 2))
  tslope = model[2] / SEslope
  sigslope = 2 * (1 - pt(abs(tslope), DF))
  SEintercept = S * sqrt((1 / length(y) + mean(x) ^ 2 / sum((x - mean(
    x
  )) ^ 2)))
  tintercept = model[1] / SEintercept
  sigintercept = 2 * (1 - pt(abs(tintercept), DF))
  RES = c(SEslope,
          tslope,
          sigslope,
          SEintercept,
          tintercept,
          sigintercept)
  names(RES) = c("SE slope",
                 "T slope",
                 "sig slope",
                 "SE intercept",
                 "t intercept",
                 "sig intercept")
  RES
}

round(Significance(iris$Petal.Length, iris$Petal.Width, model), 3)

summary(iris.lm)
```


#### Links

Learning Predictive Analytics with R, Eric Mayor, Packtpub 2015