---
title: 'DSCI354-451 practicum: 06b, Summary Statistics and Visualization'
subtitle: "Profs: R. H. French, L. S. Bruckman, P. Leu, K. Davis, S. Cirlos"
author: "TAs: W. Oltjen, K. Hernandez, M. Li, M. Li, D. Colvin" 
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: TRUE
    number_sections: TRUE
    toc_depth: 6
    highlight: tango
  html_notebook:
  html_document:
    css: ../lab.css
    highlight: pygments
    theme: cerulean
    toc: yes
    toc_depth: 6
    toc_float: yes
    df_print: paged
urlcolor: blue
---
 \setcounter{section}{6}
 \setcounter{subsection}{2}
 \setcounter{subsubsection}{5}

#### setup for r-code chunks

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = FALSE, # if TRUE knitr will cache results to reuse in future knits
  fig.width = 6, # the width for plots created by code chunk
  fig.height = 4, # the height for plots created by code chunk
  fig.align = 'center', # how to align graphics. 'left', 'right', 'center'
  dpi = 300, 
  dev = 'png', # Makes each fig a png, and avoids plotting every data point
  # eval = FALSE, # if FALSE, then the R code chunks are not evaluated
  # results = 'asis', # knitr passes through results without reformatting
  echo = TRUE, # if FALSE knitr won't display code in chunk above it's results
  message = TRUE, # if FALSE knitr won't display messages generated by code
  strip.white = TRUE, # if FALSE knitr won't remove white spaces at beg or end of code chunk
  warning = TRUE, # if FALSE knitr won't display warning messages in the doc
  error = TRUE) # report errors
  # options(tinytex.verbose = TRUE)
```


```{r,echo=TRUE, message=TRUE}
options("digits" = 5)
options("digits.secs" = 3)
library(learningr)
library(plyr)
library(dplyr)
library(reshape2)
```

#### Assignments and Comments on Code?

  - We've been reading Hadley's [R for Data Science](http:\\r4ds.had.co.nz)
  
Now that we've cleaned and have dataframes 

  - Lets get some summary statistics
  - And do some data visualization

#### Useful Tidyverse and Other Packages for Manipulation

##### Subsetting and data.table

  - http://adv-r.had.co.nz/Subsetting.html 
  - http://educate-r.org/2014/01/06/FavDataTable/
  
##### plyr and dplyr 

  - http://cran.r-project.org/web/packages/plyr/index.html 
  - http://cran.r-project.org/web/packages/dplyr/index.html 
  - http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html 
  - http://blog.rstudio.org/2014/01/17/introducing-dplyr/ 
  - http://educate-r.org/2014/01/24/usePlyr/

#### Today's goals

  - Be able to calculate a range of summary statistics on numeric data
  - Be able to draw standard plots in R’s two plotting systems
  - Be able to manipulate those plots in simple ways

##### Summary Statistics

- We’ve already come across many of the functions 

  - for calculating summary statistics, 
  - so this section is partly a recap. 

Most are fairly obvious in their naming and their usage; for example, 

  - `mean` and `median` calculate their respective measures of location. 

There isn’t a function for the mode, 

  - but it can be calculated from the results 
    - of the table function, 
    - which gives counts of each element. 

In the following examples, the obama_vs_mccain dataset, 

  - from the Learning R package, 
  - contains the fractions of people voting for Obama and McCain 
  - in the 2008 US presidential elections, 
  - along with some contextual background information on demographics:

##### `mean`, `median`

```{r}
data(obama_vs_mccain, package = "learningr")
obama <- obama_vs_mccain$Obama
mean(obama)
median(obama)
```

##### table and cut

- The table function `table` doesn’t make a great deal of sense 

  - for the obama variable (or many numeric variables) 
  - since each value is unique. 

```{r} 
help(table)
```

By combining `table` function with `cut`, 

  - we can see how many values fall into different bins:

```{r}
help(cut)
```

```{r}
table(cut(obama, seq.int(0, 100, 10)))
```

##### `var`, `sd` and `mad`

- `var` and `sd` calculate 

  - the variance and standard deviation, respectively. 

Slightly less common is the `mad` function 

  - for calculating the mean absolute deviation:

```{r}
var(obama)
sd(obama)
mad(obama)
```

##### `min`, `max` and `pmin` and `pmax`, and `range`

- There are several functions for getting the extremes of numeric data. 

  - `min` and `max` are the most obvious, 
  - giving the smallest and largest values 
    - of all their inputs, respectively.

`pmin` and `pmax` (the “parallel” equivalents) 

  - calculate the smallest and largest values at each point 
    - across several vectors of the same length. 

Meanwhile, the `range` function 

  - gives the minimum and maximum in a single function call:

```{r}
min(obama)
with(obama_vs_mccain, pmin(Obama, McCain))
range(obama)
```

##### `cummin` and `cummax`, `cumsum` and `cumprod`

- Provide cumulative results

`cummin` and `cummax` provide 

  - the smallest and largest values so far in a vector. 

Similarly, `cumsum` and `cumprod` 

  - provide sums and products of the values to date. 

These functions make most sense 

  - when the input has been ordered in a useful way:

```{r}
cummin(obama)
cumsum(obama)
cumprod(obama)
```

##### `quantile`

- The `quantile` function provides, 

  - as you might expect, 
  - quantiles (median, min, and max are special cases). 

It defaults to 

  - the median, minimum, maximum, and lower and upper quartiles, 
    - and in an impressive feat of overengineering, 
    - it gives a choice of nine different calculation algorithms:

```{r}
quantile(obama)
quantile(obama, type = 5)    #to reproduce SAS results
quantile(obama, c(0.9, 0.95, 0.99)) 
```

##### `IQR`

- `IQR` wraps quantile 

  - to give the interquartile range 
  - (the 75th percentile minus the 25th percentile):

```{r}
IQR(obama)
```

##### `fivenum`

- `fivenum` provides a faster, greatly simplified alternative to quantile. 

  - You only get one algorithm, 
  - and only the default quantiles can be calculated. 

It has a niche use where speed matters:

```{r}
fivenum(obama)
```

##### `summary`

- There are some shortcuts for calculating multiple statistics at once. 

You’ve already met the summary function, 

  - which accepts vectors or data frames:

```{r}
summary(obama_vs_mccain)
```

##### `cor`, `cancor` and `cov` 

- The `cor` function calculates 

  - correlations between numeric vectors. 

As you would expect, there was an almost perfect negative correlation 

  - between the fraction of people voting for Obama 
  - and the fraction of people voting for McCain. 

(The slight imperfection is caused by voters for independent candidates.) 

The `cancor` function 

  - (short for “canonical correlation”) 
  - provides extra details. 

And the `cov` function 

  - calculates covariances:

```{r}
with(obama_vs_mccain, cor(Obama, McCain))
with(obama_vs_mccain, cancor(Obama, McCain))
with(obama_vs_mccain, cov(Obama, McCain))
```

The `with` function 

  - lets us evaluate an expression in a data environment
  
```{r}
?with
```

#### Visualization

##### The three plotting systems in R

  - Base graphics: used often, but not pretty
  - Lattice graphics: an improvement, but cryptic, you can ignore 
  - ggplot2: grammar of graphics, great plotting system, learn this 
  
So we will focus on base graphics and ggplot2 graphics
  
Over its lifetime, R has accumulated three different plotting systems. 

base graphics are the oldest system, 
  
  - having been around as long as R itself. 
  - base graphs are easy to get started with, 
    - but they require a lot of fiddling and magic incantations to polish, 
    - and are very hard to extend to new graph types.

We'll ignore the lattice graphics, which is also built on the grid system.

The ggplot2 system, 

  - also built on top of grid, 
  - is the most modern of the three plotting systems. 

The “gg” stands for “grammar of graphics,'' 

  - which aims to break down graphs into component chunks. 

The result is that code for a ggplot 

  - looks a bit like the English way of articulating what you want in the graph.

  http://blog.revolutionanalytics.com/2009/09/ggplot2-and-the-grammar-of-graphics.html 
  
  https://ramnathv.github.io/pycon2014-r/visualize/ggplot2.html 
  
  See "A Layered Grammar of Graphics" by Hadley Wickham, 
  
    - in 3-readings in your repo.
    - 1000JCGS-wickham_layered-grammar.pdf

The three systems are, sadly, mostly incompatible 

  - there are ways to combine base and grid graphics, 
  - but they should be considered a last resort. 

The good news is that you can do almost everything you want in ggplot2, 

  - so learning all three systems is mostly overkill. 

There are a couple of rare use cases where ggplot2 isn’t appropriate: 

  - it does more calculation than other graphics systems, 
  - so for quick and dirty plots of very large datasets 
    - it can be more convenient to use another system. 

Also, many plotting packages are based on one of the other two systems, 

  - so using those packages requires a little knowledge of base or lattice.

The following examples demonstrate just base and ggplot2; 

  - if you are pushed for time, then just take note of the ggplot2 parts. 
  - This gives a taste of some of the possibilities on offer. 

Fortunately, there are three excellent and easy to read books 

  - on graph drawing in R, 
    - namely R Graphics, ggplot2, and Lattice, 
  - by the authors of the grid, ggplot2, and lattice systems, respectively.

So we'll exemplify base and ggplot2 graphics for visualization

#### Scatterplots

##### base graphics

- Perhaps the most common of all plots is the scatterplot, 

  - used for exploring the relationships between two continuous variables. 

The obama_vs_mccain dataset has lots of numeric variables that we can compare, 

  - but we’ll start by asking, “Does voter income affect turnout at the polls?”

The base graphic function to draw a scatterplot is simply plot. 

  - The best-practice code style these days 
    - is to keep all the variables you want for a plot together 
    - inside a data frame (or possibly several), 
    - rather than having them scattered in individual vectors.

Unfortunately, plot predates this idea, 

  - so we have to wrap it in a call 
  - to "with"" to access the columns.

Although plot will simply ignore missing values, 

  - for tidiness let’s remove the rows with missing Turnout values:

```{r}
obama_vs_mccain <-
  obama_vs_mccain[!is.na(obama_vs_mccain$Turnout), ]
```

We can then create a simple scatterplot:

```{r}
with(obama_vs_mccain, plot(Income, Turnout))
```

###### colors

- Plot has many arguments for customizing the output, 
  
  - some of which are more intuitive than others. 
  - col changes the color of the points. 

It accepts any of the named colors returned by colors, 

  - or an HTML-style hex value like "#123456". 
  - You can change the shape of the points with the pch argument 
    - (short for “plot character”). 

This shows an updated scatterplot, 

  - changing the point color to violet and 
  - the point shape to filled-in circles:

```{r}
with(obama_vs_mccain, plot(Income, Turnout, col = "violet", pch = 20))
```

###### log scales

- Log scales are possible by setting the log argument. 

  - log = "x" means use a logarithmic x-scale, 
  - log = "y" means use a logarithmic y-scale, 
  - and log = "xy" makes both scales logarithmic. 

This displays some options for log-scaled axes:

```{r}
with(obama_vs_mccain, plot(Income, Turnout, log = "y"))

with(obama_vs_mccain, plot(Income, Turnout, log = "xy"))
```

We can see that there is a definite positive correlation 

  - between income and turnout, 
  - and it’s stronger on the log-log scale. 

A further question is, “Does the relationship hold across all of the USA?” 

  - To answer this, we can split the data up 
    - into the 10 Standard Federal Regions 
    - given in the Region column, 
    - and plot each of the subsets in a “matrix” in one figure. 

The layout function is used 

  - to control the layout of the multiple plots in the matrix. 

Don’t feel obliged to spend a long time 

  - trying to figure out the meaning of the next code chunk; 
  - it only serves to show that drawing 
    - multiple related plots together in base graphics is possible. 

Sadly, the code invariably looks like it fell out of the proverbial ugly tree, 

  - so this technique should only be used as a last resort. 
  - Here's the result:

```{r}
par(
  mar = c(3, 3, 0.5, 0.5),
  oma = rep.int(0, 4),
  mgp = c(2, 1, 0)
)
regions <- levels(obama_vs_mccain$Region)
plot_numbers <- seq_along(regions)
layout(matrix(plot_numbers, ncol = 5, byrow = TRUE))
for (region in regions) {
  regional_data <- subset(obama_vs_mccain, Region == region)
  with(regional_data,  plot(Income, Turnout))
}
```

##### ggplot2 graphics

- ggplot2 (the “2” is because it took a couple of attempts to get it right) 

  - takes many of the good ideas in lattice and builds on them. 

So, splitting plots up into panels is easy, 

  - and sequentially building plots is also possible. 
  
Beyond that, ggplot2 has a few special tricks of its own. 

Most importantly, its “grammatical” nature means that 

  - it consists of small building blocks, 
  - so it’s easier to create brand new plot types, 
    - if you feel so inclined. 

The syntax is a very different to other plotting code, 

  - so mentally prepare yourself to look at something new. 

Each plot is constructed with a call to the ggplot function, 

  - which takes a data frame as its first argument 
  - and an aesthetic as its second. 
  
In practice, that means 

  - passing the columns for the x and y variables 
    - to the aes function. 
  - We then add a geom to tell the plot to display some points. 
  
Here is the result: 

```{r}

library(ggplot2)
ggplot(obama_vs_mccain, aes(Income, Turnout)) +
  geom_point() 
```

###### same color/shape commands as base

- ggplot2 recognizes the commands from base 

  - for changing the color and shape of the points, 
  - but also has its own set of more human-readable names. 

In this figure, 

  - “shape” replaces “pch,” and 
  - color can be specified using either “color” or “colour”:

```{r}
ggplot(obama_vs_mccain, aes(Income, Turnout)) +
  geom_point(color = "violet", shape = 20) 
```

###### log scales

- To set a log scale, we add a scale for each axis, as seen in the next figure. 

The breaks argument specifies the locations of the axis ticks. 

It is optional, but used here to replicate the behavior of the base and +lattice examples:

```{r}
ggplot(obama_vs_mccain, aes(Income, Turnout)) +
  geom_point() +
  scale_x_log10(breaks = seq(2e4, 4e4, 1e4)) +
  scale_y_log10(breaks = seq(50, 75, 5))
```

###### individual panels using "facets""

- To split the plot into individual panels, we add a facet. 

Like the lattice plots, facets take a formula argument. 

The next figure demonstrates the facet_wrap function. 

For easy reading, 

  - the x-axis ticks have been rotated by 30 degrees 
  - and right-justified using the theme function:

```{r}
ggplot(obama_vs_mccain, aes(Income, Turnout)) +
  geom_point() +
  scale_x_log10(breaks = seq(2e4, 4e4, 1e4)) +
  scale_y_log10(breaks = seq(50, 75, 5)) +
  facet_wrap(~ Region, ncol = 5) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

To split by multiple variables, 

  - we would specify a formula like ~ var1 + var2 + var3. 

For the special case of splitting by exactly two variables, 
  
  - facet_grid provides an alternative that 
  - puts one variable in rows and one in columns.

As with lattice, ggplots can be stored in variables and added to sequentially. 

The next example redraws the figure 

  - and stores it as a variable. 

As usual, wrapping the expression in parentheses 

  - makes it auto-print:

This figure shows the output

```{r}
  (gg1 <- ggplot(obama_vs_mccain, aes(Income, Turnout)) + 
    geom_point()
  )
```

This plot is stored as a variable that is reused in the next figure.

We can then update it as follows, 

  - with the result shown:

```{r}
  (gg2 <- gg1 +
    facet_wrap(~ Region, ncol = 5)
)
```

This plot reuses a ggplot2 variable from the previous figure.

#### Lineplots

- For exploring how a continuous variable changes over time, 
  
  - a line plot often provides more insight than a scatterplot, 
  - since it displays the connections between sequential values. 

These next examples examine a year in the life 

  - of the crab in the crab_tag dataset, 
  - and how deep in the North Sea it went.

##### base graphics

- In base, line plots are created in the same way as scatterplots, 

  - except that they take the argument type = "l". 

To avoid any dimensional confusion 

  - we plot the depth as a negative number 
  - rather than using the absolute values given in the dataset.

Ranges in the plot 

  - default to the ranges of the data 
    - plus a little bit more; 
    - see the x-axis section of the ?par help page for the exact details. 

To get a better sense of perspective, 

  - we’ll manually set the y-axis limit 
    - to run from the deepest point that the crab went in the sea up to sea level, 
    - by passing a ylim argument. 
  The next figure displays the resulting line plot:

```{r}
  with(
    crab_tag$daylog,
    plot(Date, -Max.Depth, type = "l", ylim = c(-max(Max.Depth), 0))
  )
  with(
    crab_tag$daylog,
    lines(Date, -Min.Depth, col = "blue")
  )
```

At the moment, this only shows half the story. 

  - The Max.Depth argument is the deepest point in the sea 
    - that the crab reached on a given day. 

We also need to add a line for the Min.Depth 

  - to see the shallowest point on each day. 

Additional lines can be drawn on an existing plot using the lines function. 

The equivalent for scatterplots is points. 

Lets see the figure with the additional line:


##### ggplot2 graphics

- In ggplot2, swapping a scatterplot for a line plot 

  - is as simple as swapping geom_plot for geom_line 

(This shows the result):

```{r}
  ggplot(crab_tag$daylog, aes(Date, -Min.Depth)) +
    geom_line() 
```

There’s a little complication with drawing multiple lines, however. 

When you specify aesthetics in the call to ggplot, 

  - you specify them for every geom. 

That is, they are “global” aesthetics for the plot. 

In this case, we want to specify 

  - the maximum depth in one line 
  - and the minimum depth in another. 

One solution to this is to 

  - specify the y-aesthetic inside each call to geom_line:

```{r}
  ggplot(crab_tag$daylog, aes(Date)) +
    geom_line(aes(y = -Max.Depth)) +
    geom_line(aes(y = -Min.Depth))
```

This is a bit clunky, though, 

  - as we have to call geom_line twice, 
  - and actually it isn’t a very idiomatic solution. 

The “proper” ggplot2 way of doing things, 

  - shown in in the next figure, 
  - is to melt the data to long form 
    - and then group the lines:

```{r}
  library(reshape2)
  crab_long <- melt(
    crab_tag$daylog, 
    id.vars      = "Date", 
    measure.vars = c("Min.Depth", "Max.Depth")
  )
  ggplot(crab_long, aes(Date, -value, group = variable)) +
    geom_line()
```

In this case, where there are only two lines, 

  - there is an even better solution 
    - that doesn’t require any data manipulation. 
  - geom_ribbon plots two lines, and the contents in between. 

For prettiness, 

  - we pass the color and fill argument to the geom, 
  - specifying the color of the lines and the bit in between. 

This shows the result:

```{r}
  ggplot(crab_tag$daylog, aes(Date, ymin = -Min.Depth, ymax = -Max.Depth)) +
    geom_ribbon(color = "black", fill = "white") 
```

Whichever system you use to draw the plot, 

  - the behavior of the crab is clear. 

In September it lives in shallow waters for the mating season, 

  - then it spends a few months migrating into deeper territory. 
  - Through winter, spring, and summer 
    - it happily sits on the North Sea seabed 
    - (except for an odd, brief trip to the surface at the start of June
      - dodgy data, or a narrow escape from a fishing boat?), 
    - then it apparently falls off a cliff in mid-July, 
    - before making its way back to shallow climes 
    - for another round of rumpypumpy, at which point it is caught.


#### Histograms

- If you want to explore the distribution of a continuous variable, 

  - histograms are the obvious choice.

Dataviz purists often note that [kernel density plots](https://en.wikipedia.org/wiki/Kernel_density_estimation) 

  - generally give a “better” representation of the underlying distribution. 
  -The downside is that every time you show them to a non-statistician, 
    - you have to spend 15 minutes explaining what a kernel density plot is.

##### base graphics

- For the next examples we’ll return to the obama_vs_mccain dataset, 

  - this time looking at the distribution of the percentage of votes for Obama. 

In base, the `hist` function draws a histogram. 

Like `plot`, it doesn’t have a data argument, 

  - so we have to wrap it inside a call to with:

```{r}
  with(obama_vs_mccain, hist(Obama))
```

The number of breaks is calculated by default by Sturges’s algorithm. 

It is good practice to experiment with the width of bins 

  - in order to get a more complete understanding of the distribution. 

This can be done in a variety of ways: 

  - you can pass hist a single number to specify the number of bins, 
  -  or a vector of bin edges, 
  - or the name of a different algorithm for calculating the number of bins 
    - ("scott" and "fd" are currently supported on top of the default of "sturges"), 
  - or a function that calculates one of the first two options. 

It’s really flexible. In the following examples, 

  - the results of which are shown in in the next 5 figures
  - the main argument creates a main title above the plot. 

It works for the plot function too:

```{r}
    with(obama_vs_mccain, 
      hist(Obama, 4, main = "An exact number of bins")
  )
  ```

```{r}
  with(obama_vs_mccain, 
    hist(Obama, seq.int(0, 100, 5), main = "A vector of bin edges")
  )

```

```{r}
  with(obama_vs_mccain, 
    hist(Obama, "FD", main = "The name of a method")
  )
```

```{r}
  with(obama_vs_mccain, 
    hist(Obama, nclass.scott, main = "A function for the number of bins")
  )
```

```{r}
  binner <- function(x) 
  {
    seq(min(x, na.rm = TRUE), max(x, na.rm = TRUE), length.out = 50)
  }
  with(obama_vs_mccain, 
    hist(Obama, binner, main = "A function for the bin edges")
  )
```

The freq argument controls 

  - whether or not the histogram shows counts or probability densities in each bin. 

It defaults to TRUE if and only if the bins are equally spaced. 

here's the output:

```{r}
  with(obama_vs_mccain, hist(Obama, freq = FALSE))
```


##### ggplot2 graphics

- ggplot2 histograms are created by adding a histogram geom. 

  - Bin specification is simple: 
  - just pass a numeric bin width to geom_histogram. 

The rationale is to force you to manually experiment 

  - with different numbers of bins, 
  - rather than settling for the default.

Here is the usage:

```{r}
ggplot(obama_vs_mccain, aes(Obama)) +
  geom_histogram(binwidth = 5)
```

You can choose between counts and densities 

  - by passing the special names ..count.. or ..density.. to the y-aesthetic. 

This figure demonstrates the use of ..density..:

```{r}
  ggplot(obama_vs_mccain, aes(Obama, ..density..)) +
    geom_histogram(binwidth = 5)
```


#### Boxplots

- If you want to explore the distribution of lots of related variables, 

  - you could draw lots of histograms. 

For example, if you wanted to see the distribution of Obama votes by US region, 

  - you could use latticing/faceting to draw 10 histograms. 

This is just about feasible, but it doesn’t scale much further. 

If you need a hundred histograms, 

  - the space requirements can easily overwhelm the largest monitor. 

Box plots (sometimes called box and whisker plots) 

  - are a more space-efficient alternative 
  - that make it easy to compare many distributions at once. 

You don’t get as much detail as with a histogram or kernel density plot, 

  - but simple higher-or-lower and narrower-or-wider comparisons can easily be made. 

##### base graphics

- The base function for drawing box plots is called boxplot; 

  - it is heavily inspired by lattice, 
  - insofar as it uses a formula interface and has a data argument. 
  
This shows the usage:

```{r}
  boxplot(Obama ~ Region, data = obama_vs_mccain)
```

This type of plot is often clearer 

  - if we reorder the box plots from smallest to largest, in some sense. 

The reorder function changes the order of a factor’s levels, 

  - based upon some numeric score. 

In this figure we score the Region levels 

  - by the median Obama value for each region:

```{r}
  ovm <- within(
    obama_vs_mccain, 
    Region <- reorder(Region, Obama, median)
  )
  boxplot(Obama ~ Region, data = ovm)
```

##### ggplot2 graphics

- The ggplot2 equivalent box plot, shown next, 

  - just requires that we add a geom_boxplot:

```{r}
  ggplot(ovm, aes(Region, Obama)) +
    geom_boxplot()
```

#### Barcharts

- Bar charts (a.k.a. bar plots) are the natural way of 

  - displaying numeric variables 
  - split by a categorical variable. 

In the next examples, we look at 

  - the distribution of religious identification across the US states. 

Data for Alaska and Hawaii are not included in the dataset, 

  - so we can remove those records:

```{r}
  ovm <- ovm[!(ovm$State %in% c("Alaska", "Hawaii")), ]
# remove Alaska and Hawaii from the dataframe
```



##### base graphics

- In base, bar charts are created with the barplot function. 

  - As with the plot function, 
    - there is no argument to specify a data frame, 
  - so we need to wrap it in a call to with. 

The first argument to barplot contains the lengths of the bars. 

If that is a named vector 

  - (which it won’t be if you are doing things properly 
    - and accessing data from inside a data frame), 
  - then those names are used for the bar labels. 

Otherwise, as we do here, 

  - you need to pass an argument called names.arg to specify the labels. 

By default the bars are vertical, 

  - but in order to make the state names readable we want horizontal bars, 
  - which can be generated with horiz = TRUE.

To display the state names in full, 

  - we also need to do some fiddling with the plot parameters, 
    - via the par function. 
  - For historical reasons, most of the parameter names are abbreviations 
    - rather than human-readable values, so the code can look quite terse. 

It’s a good idea to read the ?par help page before you modify a base plot.

```{r}
?par
```

The `las` parameter 

  -  (short for “label axis style”) 
  - controls whether labels are 
    - horizontal, vertical, parallel, or perpendicular to the axes. 

Plots are usually more readable if you set las = 1, for horizontal. 

The `mar` parameter 

  - is a numeric vector of length 4, 
  - giving the width of the plot margins 
    - at the bottom/left/top/right of the plot. 

We want a really wide left hand side to fit the state names. 

This figure shows the output of the following code:

```{r}
  par(las = 1, mar = c(3, 9, 1, 1))
  with(ovm, barplot(Catholic, names.arg = State, horiz = TRUE))
```

Simple bar charts like this are fine, 

  - but more interesting are bar charts of several variables at once. 

We can visualize the split of religions by state 

  - by plotting the Catholic, Protestant, Non.religious, and Other columns. 

For plotting multiple variables, 

  - we must place them into a matrix, 
  - one in each row (rbind is useful for this).

The column names of this matrix are used for the names of the bars; 

  - if there are no column names 
  - we must pass a names.arg like we did in the last example. 

By default, the bars for each variable are drawn next to each other, 

  - but since we are examining the split between the variables, 
  - a stacked bar chart is more appropriate. 

Passing beside = FALSE achieves this, as illustrated in the next figure:

```{r}
  religions <- with(ovm, rbind(Catholic, Protestant, Non.religious, Other))
  colnames(religions) <- ovm$State
  par(las = 1, mar = c(3, 9, 1, 1))
  barplot(religions, horiz = TRUE, beside = FALSE)
```

##### ggplot2 graphics

- ggplot2 requires a tiny bit of work be done to the data to replicate this plot. 

We need the data in long form, 

  - so we must first melt the columns that we need:

```{r}
  religions_long <- melt(
    ovm, 
    id.vars = "State",
    measure.vars = c("Catholic", "Protestant", "Non.religious", "Other")
  )
```

Like base, gplot2 defaults to vertical bars; 

  - adding coord_flip swaps this. 

Finally, since we already have the lengths of each bar in the dataset 

  - (without further calculation) 
  - we must pass stat = "identity" to the geom. 

Bars are stacked by default, as shown in this figure:

```{r}
  ggplot(religions_long, aes(State, value, fill = variable)) +
    geom_bar(stat = "identity") +
    coord_flip()
```

To avoid the bars being stacked, 

  - we would have to pass the argument position = "dodge" to geom_bar. 

```{r}
  ggplot(religions_long, aes(State, value, fill = variable)) +
    geom_bar(stat = "identity", position = "dodge") +
    coord_flip()
```

#### Other graphics systems

- There are many packages that contain plotting capabilities 

  - based on one or more of the three systems. 

For example, the vcd package has lots of plots 

  - for visualizing categorical data, 
  - such as mosaic plots and association plots. 

plotrix has loads of extra plot types, 

  - and there are specialist plots scattered in many other packages. 

latticeExtra and GGally extend the lattice and ggplot2 packages, 

  - and grid provides access to the underlying framework that supports both these systems.

#### interactive visualization

You may have noticed that all the plots covered so far are static. 

There have in fact been a number of attempts 

  - to provide dynamic and interactive plots.9 

There is no perfect solution yet, 

  - but there are many interesting and worthy packages that attempt this.

gridSVG lets you write grid-based plots (lattice or ggplot2) to SVG files. 

These can be made interactive, 

  - but it requires some knowledge of JavaScript. 
    - playwith allows pointing and clicking to interact with base or lattice plots. 
    - iplots provides a whole extra system of plots with even more interactivity. 
  - It isn’t easily extensible, but the common plots types are there, 
    - and you can explore the data very quickly via mouse interaction. 

googleVis provides an R wrapper around Google Chart Tools, 

  - creating plots that can be displayed in a browser. 

rggobi provides an interface to 

  - GGobi (for visualizing high-dimensional data), and 
  
rgl provides an interface to OpenGL 

  - for interactive 3D plots. 
  
The animation package 

  - lets you make animated GIFs or SWF animations.

#### Interfacing to d3 javascript graphics

- The r2d3 package provides an interface to javascript d3 visualizations

  - [d3 Data Driven Documents](https://d3js.org/)
  - [A gallery of d3 graphics](https://github.com/d3/d3/wiki/Gallery)
  - [And on Observable](https://observablehq.com/collection/@observablehq/visualization)



#### Summary

  - There are loads of summary statistics that can be calculated.
  - R has three plotting systems: base, lattice, and ggplot2.
  - All the common plot types are supported in every system.
  - There is some support in R for dynamic and interactive plotting.


#### Cites

examples from 

  - Learning R, by Richard Cotton, 2013, O’Reilly Media, Inc.